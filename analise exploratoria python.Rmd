---
title: <p style="text-align:center"><img src="https://s1.static.brasilescola.uol.com.br/be/vestibular/graficos-tabelas-sao-objetos-basicos-para-estudo-estatistica-5812154677e56.jpg" width="1200" height="260" /></p>
  
  
  **Análise Exploratória Em Python** 
author: "joseferson da silva barreto"
date: "07/11/2021"
output:
    html_document:
        #css: arquivo.css
---


# Objetivo
Realizar uma análise exploratória affim de responder algumas questões , para estem fim usaremos os dados  públicos disponíveis no  IMDB sobre as avaliações dos filmes . 

<font color='#e6103e' > As principais pergutas que buscaremos respostas: </font> 

1- Quais São as Categorias de Filmes Mais Comuns no IMDB?

2- Qual o Número de Títulos Por Gênero?

3- Qual o Número de Filmes Produzidos Por País?



4- Quais São os Top 10 Melhores Filmes?


5- Quais São os Top 10 Piores Filmes?


# Escolhendo o diretório  e chamando a liguagem python

Para podermos utilizar a liguagem pyhon  no Rmarkdown vamos chamar o pacote "**reticulate**"


```{r results='asis', echo=FALSE, include=FALSE,}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(reticulate)
#py_install("IPython")



```


# Carregando pacotes 
Agora vamos carregar os pacotes python necessários  para a nossa análise  

```{python}
# Imports


import re
import time
import sqlite3
import pycountry
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import cm
from IPython.display import display
from sklearn.feature_extraction.text import CountVectorizer
import warnings
warnings.filterwarnings("ignore")
sns.set_theme(style = "whitegrid")
```

# fazendo  download do banco de dados  publico do  IMDB

As seguintes linhas de comando abaixo  faz o download do banco de dados do IMDB  , para  utilizar remova as "#" 
 depois de baixado,coloque a  "#" novamente.
 É possível utilizar os comandos abaixo  pelo o próprio CMD,caso queira .

```{python}
#!imdb-sqlite
```

   
# Conectando  o banco dedos SQlite

Para conectar ao artquivo "db"  vamos utilizar o comando "**sqlite3.connect()**"da do pacote  **sqlite3** , além disso , para podermos utilizar o arquivo SQl temos que indicar o caminho onde o arquivo "db" está localizado 
          
```{python}
# Conecta no banco de dados
conn = sqlite3.connect("C:/Users/josef/Documents/PythonFundamentos-master/Cap06/Notebooks/imdb.db")
```




#  Gerando o data frame 

 O comando "**pd.read_sql_query**" do pacote "pandas"  gera o nosso  data frame
 onde os argumentos  "SElECT  AS " ,"FROM"   ,"WHERE"   são argumentos da linguagem  SQL para seleção e "conn"  é a variavél criada anteriomente     que está conectada ao  servidor Sql .  
```{python}
import pandas as pd
import sqlite3







# Extrai a lista de tabelas
tabelas = pd.read_sql_query("SELECT NAME AS 'Table_Name' FROM sqlite_master WHERE type = 'table'", conn)
```



# visualiza o  tipo  do objeto 
 visualiza o tipo de objeto que nosso caso é um DataFrame 
```{python}
# Tipo do objeto
#type(tabelas)
```




   


## Visualiza o resultado

```{python}
# Visualiza o resultado
tabelas.head()
```


## Covertendo  o nosso DataFrame em lista 

O comando "**values.tolist()**"  é responsável pela conversão  de DataFrame para lista.
```{python}
# Vamos converter o dataframe em uma lista
tabelas = tabelas["Table_Name"].values.tolist()
```


# criando um loop 

 O loop vai funcionar da seguinte forma , para cada tabela na lista de tabelas ,vamos buscar os detalhes da tabela,logo,fazemos  uma "consulta" ,na sequência buscaremos os "resultados" ,  o próximo passo  imprime(print) 
o nome da  tabela e o resultado **display(resultado)**  além disso , imprimimos uma quebra de linha  para que sejá visivél todas as tabelas .
 
```{python}


# Vamos percorrer a lista de tabelas no banco de dados e extrair o esquema de cada uma


for tabela in tabelas:
    consulta = "PRAGMA TABLE_INFO({})".format(tabela)
    resultado = pd.read_sql_query(consulta, conn)
    print("Esquema da tabela:", tabela)
    display(resultado)
    print("-"*100)
    print("\n")
 
   
```






  
    
  
    
     

    
   

  
      
    
    
    
 Logo , teremos o esquema com os valores de cada tabela: pessoas(people), ou seja ,os atores que participaram dos filmes 
 a tabela titulos(titles) que são os nomes dos filmes , a tabela "akas" que contem a região e o idioma dos  filmes , a tabela  "crew" que é as equipes que participaram na criação dos filmes  , a tabela "episodes" que contem informações sobre séries ,documentários ,sagas  e por último temos  a tabela de avaliações(ratings)
    

> Agora começamos a Análise Exploratória dos Dados.

## 1- Quais São as Categorias de Filmes Mais Comuns no IMDB?

<font color='red'> Quais são os principais tipos (categorias) dos títulos (filmes)?</font>

Primeiramente vamos realizar uma consulta a nossa fonte de dados  , para isso vamos utilizar uma instrução Sql 
**SELECT type** onde "type" é a categoria ,"COUNT(*)"  numero de registros ,   **FROM titles** ,ou seja, para a tabela "titles"  agrupando por tipo **GROUP BY type**.
```{python,message=FALSE}
# Cria a consulta SQL
consulta1 = '''SELECT type, COUNT(*) AS COUNT FROM titles GROUP BY type''' 
```



# Extraindo os resultados 

vamos retornar o conjunto de resultados da string de consulta  pelo comando **pd.read_sql_query()**,nesse caso, 
vamos executar a consulta(consulta1)   da nossa conexão(conn).

```{python}
# Extrai o resultado
resultado1 = pd.read_sql_query(consulta1, conn)
```



# Visualizando os resultados 
 para   visualizar os resultados vamos utilizar o comando display() , caso dê erro , execute a seguinte linha de comandos no carregamento de pacotes python **from IPython.display import display**.

```{python,eval=FALSE}
# Visualiza o resultado
display(resultado1)
```

```{r,echo=FALSE,message=FALSE}
 library(gt)
library(dplyr)

l<-py$resultado1
 l %>% gt()

```
   
#    calculando o percentual para cada tipo 

 resultado1 irá receber uma nova variável(percentual)  que nada mais é que cada total de registros dividido pela soma 
 de registros multiplicado por 100 

```{python}
# Vamos calcular o percentual para cada tipo
resultado1['percentual'] = (resultado1['COUNT'] / resultado1['COUNT'].sum()) * 100
```

Exibindo o resultado  
```{python,eval=FALSE}
# Visualiza o resultado
display(resultado1)
```

```{r,echo=FALSE}
 library(gt)
library(dplyr)
options(scipen = 999)
l<-py$resultado1
 l %>% gt()

```

# Vamos criar um gráfico com apenas 4 categorias:  
 Vamos criar um gráfico   com 4 categorias , sendo 3 delas referente  as categorias com mais títulos  e  1 categoria com todo o restante (others). Antes vamos criar um dicionario vazio onde irá fica armazenado os valores das categorias restantes , depois vamos  filtrar o percentual do (resultado1) que foram menor do que 5% 
depois vamos gravar o resultado em **others["percentual"]**.

```{python}
# Vamos criar um gráfico com apenas 4 categorias:
# As 3 categorias com mais títulos e 1 categoria com todo o restante

# Cria um dicionário vazio
others = {}

# Filtra o percentual em 5% e soma o total
others['COUNT'] = resultado1[resultado1['percentual'] < 5]['COUNT'].sum()

# Grava o percentual
others['percentual'] = resultado1[resultado1['percentual'] < 5]['percentual'].sum()

# Ajusta o nome
others['type'] = 'others'

```


## visualisando 
```{python}
# Visualiza
others
```




## Próximo passo 

Vamos filtrar os resuldos maiores que 5%, em seguida vamos adicionar "others" ao 
**resultado1**  e por último vamos ordenar (resultado1)  por  "**COUNT**"



```{python}
# Filtra o dataframe de resultado
resultado1 = resultado1[resultado1['percentual'] > 5]

# Append com o dataframe de outras categorias
resultado1 = resultado1.append(others, ignore_index = True)


# Ordena o resultado
resultado1 = resultado1.sort_values(by = 'COUNT', ascending = False)

#renomeando 
resultado1 = resultado1.rename(columns={'type': 'tipo','COUNT':'contagem'})

```

```{python,eval=FALSE}
# Visualiza
resultado1.head()
```

```{r,echo=FALSE}
 library(gt)
library(dplyr)
options(scipen = 999)
l<-py$resultado1
 l %>% gt()

```



 Logo , a categoria mais comum no IMDB é **tvEpisode**  com 73% , na segunda posição aparece   a categria   **short**

com 10%.



## Ajustandos os labels 

Para ajustar os Labels vamos utilizar list comprehension
onde que para cada índice  do DataFrame do **resultado1** retorno  a categoria(**tipo**)
e o **percentual**  .

    
```{python}
# Ajusta os labels
labels = [str(resultado1['tipo'][i])+' '+'['+str(round(resultado1['percentual'][i],2)) +'%'+']' for i in resultado1.index]
```


## Executando o gráfico de  rosca 

 Para o mapeamento das cores   vamos utilizar o "set3", depois criamos a figura , em seuida  criamos o gráfico
 atráves  do comando **plt.pie()**
 
 
 pequena descrição sobre alguns argumentos :
 
 figsize= determina o tamanho da figura 
 
 
 radius=   raio  dá circunferência 
 
 
 
 **wedgeprops = dict()** = determina o tamanho da torta   na circunferência 
 
 loc= local
 
 
 
```{python,fig.align="center", results='hide'}
# Plot

# Mapa de cores
# https://matplotlib.org/stable/tutorials/colors/colormaps.html
cs = cm.Set3(np.arange(100))

# Cria a figura
f = plt.figure(figsize = (8,8))
#f.set_size_inches(4,4)
#f.set_size_inches(6, 6, forward=True) 
# Pie Plot

plt.pie(resultado1['contagem'], labeldistance = 0.5, radius = 1.2, colors = cs, wedgeprops = dict(width = 0.4))
plt.legend(labels = labels, loc = 'center', prop = {'size':14})
plt.title("Distribuição de Títulos", loc = 'center', fontdict ={'fontsize':16,'fontweight':10})

plt.show()
```


 Como foi  dito anteriormente a categoria mais comum foi a de TvEpisode 
    

    


## 2- Qual o Número de Títulos Por Gênero?

Vamos montar uma nova consulta ao nosso banco de dados  como citado na questão 1 , dessa vez , bvamos utilizar a coluna  "genres", lembre-se que as palavras em letras maiúsculas são sintaxe Sql   e as palavras em letras minúsculas é aquilo que está presente  em nosso banco de dados .


```{python}
# Cria a consulta SQL
consulta2 = '''SELECT genres, COUNT(*) FROM titles WHERE type = 'movie' GROUP BY genres''' 
```

vamos retornar o conjunto de resultados da string de consulta  pelo comando **pd.read_sql_query()**,nesse caso, 
vamos executar a consulta(consulta2)   da nossa conexão(conn).

```{python,results='hide'}
# Resultado
resultado2 = pd.read_sql_query(consulta2, conn)
# Visualiza o resultado
display(resultado2)
```


```{python,results='hide'}
# Visualiza o resultado
display(resultado2)

```


```{r,echo=FALSE}
 library(gt)
library(dplyr)
options(scipen = 999)
l<-py$resultado2
 
k<-head(l)
colnames(k)[1] <- "genero"

      u<-as.data.frame(seq(1:6))

   colnames(u)[1]<-"N"
    ju<-cbind(u,k)
    
ju %>% gt()
```


 Como  podemos ver ,  alguns filmes estão com mais de um gênero, logo,     vamos ter que  ajustar essas informações  , além disso,**\n**  indica que temos filque que não foi indicado o seu gênero,ou seja , tbm temos que resolver essa questão.
  



# Para facilitar nosso trabalho

 Vamos converter as strings 
```{python}
# Converte as strings para minúsculo
resultado2['genres'] = resultado2['genres'].str.lower().values
```

# remove os valores 

**.dropna()**  remove os valores ausentes 
```{python}
# Remove valores NA (ausentes)
temp = resultado2['genres'].dropna()
```

Usamos o Countvectorizer para converter a coluna de gêneros em um vetor one-hot encoded para contar o número de filmes em cada gênero.

Para este fim   vamos utlizar  também a expressão regular para filtrar as strings  e vamos criar ma matriz esparsa 


```{python}
# Vamos criar um vetor usando expressão regular para filtrar as strings

# https://docs.python.org/3.8/library/re.html
padrao = '(?u)\\b[\\w-]+\\b'

# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html
vetor = CountVectorizer(token_pattern = padrao, analyzer = 'word').fit(temp)
```


```{python}
#type(vetor)
```




   

# criando a matriz

```{python}
# Aplica a vetorização ao dataset sem valores NA
bag_generos = vetor.transform(temp)
```


```{python}
type(bag_generos)
```







 Obetendo  nome dos atributos através do comando **get_feature_names()** e guardando em generos_unicos
 
```{python}
# Retorna gêneros únicos
generos_unicos =  vetor.get_feature_names()
```

## Criando  um DataFrame 
Através dos comando **pd.DataFrame()** vamos criar um  data frame 

```{python}
# Cria o dataframe de gêneros
generos = pd.DataFrame(bag_generos.todense(), columns = generos_unicos, index = temp.index)
```


```{python}
# Visualiza
generos.info()
```




# <font color='red'>  **Observação**  </font>

Agora temos cada um dos gêneros de maneira individual , mas ainda temos um problema , perceba que temos uma coluna  **n** que foi gerada por acaso no processo de conversão ,então vamos removê-la.



## Removendo a coluna "n"

Para a remoção vamos utilizar o comando **drop()**.
```{python}
# Drop da coluna n
generos = generos.drop(columns = 'n', axis = 0)
```

## calculando o percentual 
 calculando o percentual e retornando os 10 principais 
```{python,echo = TRUE, results='hide'}
# Calcula o percentual
generos_percentual = 100 * pd.Series(generos.sum()).sort_values(ascending = False) / generos.shape[0]

generos_percentual.head(10)

```

```{r,echo=FALSE}
ge<-as.data.frame(py$generos_percentual)


j<-as.data.frame(row.names(ge))

gers<-cbind(j,ge)
N<-as.data.frame(seq(1:10))


colnames(gers)[1] <- "genero"

colnames(gers)[2] <- "percentual"

ger<-cbind(N,gers[1:10,])

colnames(ger)[1]<-"N"
ger%>% gt()


```

## Plotando o gráfico

Vamos tornar as coisas mais visuais plotando um gráfico 



```{python}
# Plot
plt.figure(figsize = (16,10))
sns.barplot(x = generos_percentual.values, y = generos_percentual.index, orient = "h", palette = "terrain")
plt.ylabel('Gênero')             
plt.xlabel("\nPercentual de Filmes (%)")
plt.title('\nNúmero (Percentual) de Títulos Por Gênero\n')
plt.show()

```


 Podemos perceber que o gênero "drama" é o qual detem  maior percentual de filmes mais de 18%, em segundo lugar  temos o gênero "comedy"  com 16,95%  e em terceiro aparece o gênero "documentary" com 15,92% .



  





    





    

    


## 3- Qual o Número de Filmes Produzidos Por País?
A região onde cada fime foi produzido está na tabela "akas",logo ,vamos fazer uma consulta  ao nosso banco de dados usando os conceitos vistos na questão 1  e 2 :


vamos contar  numero de flmes ,buscando os dados na tabela "akas" junto com a tabela"titles"  
 **as.title_id = titles.title_id** é a junção das tabelas 

```{python}
# Consulta SQL
consulta3 = '''
            SELECT region, COUNT(*) Number_of_movies FROM 
            akas JOIN titles ON 
            akas.title_id = titles.title_id
            WHERE region != 'None'
            AND type = \'movie\'
            GROUP BY region
            ''' 
```


## dataframe 

montando o nosso DataFrame como nas questões anteriores 

```{python,echo = TRUE, results='hide'}
# Resultado
resultado3 = pd.read_sql_query(consulta3, conn)

display(resultado3)
```

```{r,echo=FALSE}
 library(gt)
library(dplyr)
options(scipen = 999)
l<-head(py$resultado3)
 


l %>% gt()
```



      

  
  
  








   








   



## criando duas listas auxiliares

```{python}
# Listas auxiliares
nomes_paises = []
contagem = []
```


## criando um loop

o loop Para cada elemento,**resultado3.shape[0]**  garante o total de linhas mesmo que o banco de dados seja atualizado , depois vamos  utilizar o tratamento de erros  "try", "except"  para que em caso de erro , apenas continue :   vamos retirnar o nosso conjunto de dados a coluna **region**  depois vamos preencher as  listas  auxiliares **nomes_paises**  e **contagem**
```{python}
# Loop para obter o país de acordo com a região
for i in range(resultado3.shape[0]):
    try:
        coun = resultado3['region'].values[i]
        nomes_paises.append(pycountry.countries.get(alpha_2 = coun).name)
        contagem.append(resultado3['Number_of_movies'].values[i])
    except: 
        continue
```





##  Preparando o DataFrame 
```{python}
# Prepara o dataframe
df_filmes_paises = pd.DataFrame()
df_filmes_paises['country'] = nomes_paises
df_filmes_paises['Movie_Count'] = contagem
```





# Ordenando os resultados 

o argumento **ascending** ordena os resultados , caso use "**true**" ele vai do menor para o maior , logo temos que usar "**false**"

```{python,echo = TRUE, results='hide'}
# Ordena o resultado
df_filmes_paises = df_filmes_paises.sort_values(by = 'Movie_Count', ascending = False)

# Visualizando
df_filmes_paises.head(10)
```

```{r,echo=FALSE}
 library(gt)
library(dplyr)
options(scipen = 999)
lose<-py$df_filmes_paises
# escolhendo linhas 
 lose[1:10,]  %>%  gt()

```




## Plotando o gráfico 


Para melhor visualização vamos plotar o gráfico      
  
    

```{python}
# Plot

# Figura
plt.figure(figsize = (20,12))

# Barplot
sns.barplot(y = df_filmes_paises[:20].country, x = df_filmes_paises[:20].Movie_Count, orient = "h")

# Loop
for i in range(0,20):
    plt.text(df_filmes_paises.Movie_Count[df_filmes_paises.index[i]]-1,
             i + 0.30,
             round(df_filmes_paises["Movie_Count"][df_filmes_paises.index[i]],2))

plt.ylabel('País')             
plt.xlabel('\nNúmero de Filmes')
plt.title('\nNúmero de Filmes Produzidos Por País\n')
plt.show()
```


    
Como podemos perceber , os Estados Unidos(United States) é o pais que mais  produz filmes com  301.122 filmes produzidos , em segundo lugar temos o Reino Unido(United Kingdom ) com  mais  de 154 mil filmes produzidos  e em terceiro lugar temos o japão(Japan) com  89.646  produções.Além disso ,  o Brasil aparece na lista dos 10 países que mais produções, atualmente na nona colocação , o país possui  63.550  produções.
    


## 4- Quais São os Top 10 Melhores Filmes?

Top 10 filmes com melhor avaliação com  25 mil votos ou mais .

vamos retortnar  o título do filme como o nome do filme  , também vamos  retornar o gênero  e a avaliação  a partir da tabela titulo(titles)  juntando com a tabela avaliação(rating) com o número de votos  maior ou igual a 25 mil votos  ordenando em ordem decrescente ,ou seja , do maior para o menor ,pegando os 10 primeiros 

```{python}
# Consulta SQL
consulta4 = '''
            SELECT primary_title AS Movie_Name,genres, rating
            FROM 
            titles JOIN ratings
            ON  titles.title_id = ratings.title_id
            WHERE titles.type = 'movie' AND ratings.votes >= 25000
            ORDER BY rating DESC
            LIMIT 10          
            ''' 
```


```{python,echo = TRUE, results='hide'}
# Resultado
top10_melhores_filmes = pd.read_sql_query(consulta4, conn)

#visualizando
display(top10_melhores_filmes)
```

```{r,echo=FALSE}

 g<-py$top10_melhores_filmes
 N<-seq(1:10)
 w<-g[1:10,]
 j<-cbind(N,w)
j %>% gt()
```


## <font color='red'> Caso queira plotar um gráfico </font>





```{python}

plt.figure(figsize = (20,10))

sns.barplot(top10_melhores_filmes['rating'],top10_melhores_filmes['Movie_Name'], palette = "terrain",orient = "h")

plt.title('\n top 10 melhores filmes \n')
plt.xlabel('notas')
#
plt.show()
``` 
  
  
  
  os melhores filmes segundo as avaliações feitas no IBMI são :   
  
  1-Jai Bhim,com nota 9.7 nas avaliações 
    
  2-The Shawshank Redemption, com nota 9.3 nas avaliações
  
  3-The Chaos Class,com nota geral   9.3 nas avaliações 
  
  4-The Godfather,com nota geral  9.2 nas avalições
  
  5-Soorarai Pottru , com nota geral de 9.1 nas avaliações 
  
  6-CM101MMXI Fundamentals, com nota geral de 9.1 nas avaliações 
  
  7-Mirror Game, com nota geral de 9.1 nas avaliações 
  
  8- Angry Men, com nota geral de 9.0 nas avaliações 
  
  9-The Godfather: Part II, com nota geral  9.0 nas avaliações 
  
  10- The Dark Knight, com nota geral  9.0 nas avaliações 

## 5- Quais São os Top 10 Piores Filmes?

Top 10 filmes com pior avaliação com  25 mil votos ou mais.


```{python}
# Consulta SQL
consulta5 = '''
            SELECT primary_title AS Movie_Name, genres, rating
            FROM 
            titles JOIN ratings
            ON  titles.title_id = ratings.title_id
            WHERE titles.type = 'movie' AND ratings.votes >= 25000
            ORDER BY rating ASC
            LIMIT 10
            ''' 
```


```{python}
# Resultado
top10_piores_filmes = pd.read_sql_query(consulta5, conn)


```

## visualizando 
```{python,eval=FALSE}
display(top10_piores_filmes)


```


```{r,echo=FALSE}
 da<-py$top10_piores_filmes

N<-seq(1:10)
 w<-da[1:10,]
 j<-cbind(N,w)
j %>% gt()
```




## <font color='red'> Caso queira plotar um gráfico </font>

```{python}

plt.figure(figsize = (20,10))

sns.barplot(top10_piores_filmes['rating'],top10_piores_filmes['Movie_Name'], palette = "terrain",orient = "h")

plt.title('\n top 10 piores filmes \n')
plt.xlabel('notas')
#
plt.show()
``` 





 Os piores filmes segundo as avaliações feitas no IBMI são :  
 

                       
1-Cumali Ceber com nota geral 1.0 nas avaliações

2-Sadak 2 com nota geral 1.1 nas avaliações

3-Smolenskcom nota geral de 1.2 nas avaliações

4-The Cost of Deception  com nota geral de 1.4 nas avaliações

5-Reis com nota geral de 1.4 nas avaliações

6-Justin Bieber: Never Say Never  com nota geral  1.6 nas avaliações

7-Manos: The Hands of Fate    com nota geral  1.8 nas avaliações

8-Radhe  com nota geral  1.8 nas avaliações

9-Superbabies: Baby Geniuses 2   com nota geral 1.9 nas avaliações

10-The Hottie & the Nottie   com nota geral  1.9 nas avaliações



# Conclusão
 
 
Como podemos  perceber , podemos  utilizar a liguagem python para vários  fins,  inclusive para executar uma análise exploratória dos dados  e obter  o resultado com poucas linhas de comando .





# Link para download


Acesse o  repositório no GitHub : https://github.com/JosefersonBarreto/exploratoriaPY.git.